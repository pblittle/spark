// Code generated by ent, DO NOT EDIT.

package sparkinvoice

import (
	"time"

	"entgo.io/ent/dialect/sql"
	"entgo.io/ent/dialect/sql/sqlgraph"
	"github.com/google/uuid"
)

const (
	// Label holds the string label denoting the sparkinvoice type in the database.
	Label = "spark_invoice"
	// FieldID holds the string denoting the id field in the database.
	FieldID = "id"
	// FieldCreateTime holds the string denoting the create_time field in the database.
	FieldCreateTime = "create_time"
	// FieldUpdateTime holds the string denoting the update_time field in the database.
	FieldUpdateTime = "update_time"
	// FieldSparkInvoice holds the string denoting the spark_invoice field in the database.
	FieldSparkInvoice = "spark_invoice"
	// FieldExpiryTime holds the string denoting the expiry_time field in the database.
	FieldExpiryTime = "expiry_time"
	// FieldReceiverPublicKey holds the string denoting the receiver_public_key field in the database.
	FieldReceiverPublicKey = "receiver_public_key"
	// EdgeTokenTransaction holds the string denoting the token_transaction edge name in mutations.
	EdgeTokenTransaction = "token_transaction"
	// EdgeTransfer holds the string denoting the transfer edge name in mutations.
	EdgeTransfer = "transfer"
	// Table holds the table name of the sparkinvoice in the database.
	Table = "spark_invoices"
	// TokenTransactionTable is the table that holds the token_transaction relation/edge. The primary key declared below.
	TokenTransactionTable = "token_transaction_spark_invoice"
	// TokenTransactionInverseTable is the table name for the TokenTransaction entity.
	// It exists in this package in order to avoid circular dependency with the "tokentransaction" package.
	TokenTransactionInverseTable = "token_transactions"
	// TransferTable is the table that holds the transfer relation/edge.
	TransferTable = "transfers"
	// TransferInverseTable is the table name for the Transfer entity.
	// It exists in this package in order to avoid circular dependency with the "transfer" package.
	TransferInverseTable = "transfers"
	// TransferColumn is the table column denoting the transfer relation/edge.
	TransferColumn = "spark_invoice_id"
)

// Columns holds all SQL columns for sparkinvoice fields.
var Columns = []string{
	FieldID,
	FieldCreateTime,
	FieldUpdateTime,
	FieldSparkInvoice,
	FieldExpiryTime,
	FieldReceiverPublicKey,
}

var (
	// TokenTransactionPrimaryKey and TokenTransactionColumn2 are the table columns denoting the
	// primary key for the token_transaction relation (M2M).
	TokenTransactionPrimaryKey = []string{"token_transaction_id", "spark_invoice_id"}
)

// ValidColumn reports if the column name is valid (part of the table columns).
func ValidColumn(column string) bool {
	for i := range Columns {
		if column == Columns[i] {
			return true
		}
	}
	return false
}

var (
	// DefaultCreateTime holds the default value on creation for the "create_time" field.
	DefaultCreateTime func() time.Time
	// DefaultUpdateTime holds the default value on creation for the "update_time" field.
	DefaultUpdateTime func() time.Time
	// UpdateDefaultUpdateTime holds the default value on update for the "update_time" field.
	UpdateDefaultUpdateTime func() time.Time
	// SparkInvoiceValidator is a validator for the "spark_invoice" field. It is called by the builders before save.
	SparkInvoiceValidator func(string) error
	// DefaultID holds the default value on creation for the "id" field.
	DefaultID func() uuid.UUID
)

// OrderOption defines the ordering options for the SparkInvoice queries.
type OrderOption func(*sql.Selector)

// ByID orders the results by the id field.
func ByID(opts ...sql.OrderTermOption) OrderOption {
	return sql.OrderByField(FieldID, opts...).ToFunc()
}

// ByCreateTime orders the results by the create_time field.
func ByCreateTime(opts ...sql.OrderTermOption) OrderOption {
	return sql.OrderByField(FieldCreateTime, opts...).ToFunc()
}

// ByUpdateTime orders the results by the update_time field.
func ByUpdateTime(opts ...sql.OrderTermOption) OrderOption {
	return sql.OrderByField(FieldUpdateTime, opts...).ToFunc()
}

// BySparkInvoice orders the results by the spark_invoice field.
func BySparkInvoice(opts ...sql.OrderTermOption) OrderOption {
	return sql.OrderByField(FieldSparkInvoice, opts...).ToFunc()
}

// ByExpiryTime orders the results by the expiry_time field.
func ByExpiryTime(opts ...sql.OrderTermOption) OrderOption {
	return sql.OrderByField(FieldExpiryTime, opts...).ToFunc()
}

// ByTokenTransactionCount orders the results by token_transaction count.
func ByTokenTransactionCount(opts ...sql.OrderTermOption) OrderOption {
	return func(s *sql.Selector) {
		sqlgraph.OrderByNeighborsCount(s, newTokenTransactionStep(), opts...)
	}
}

// ByTokenTransaction orders the results by token_transaction terms.
func ByTokenTransaction(term sql.OrderTerm, terms ...sql.OrderTerm) OrderOption {
	return func(s *sql.Selector) {
		sqlgraph.OrderByNeighborTerms(s, newTokenTransactionStep(), append([]sql.OrderTerm{term}, terms...)...)
	}
}

// ByTransferCount orders the results by transfer count.
func ByTransferCount(opts ...sql.OrderTermOption) OrderOption {
	return func(s *sql.Selector) {
		sqlgraph.OrderByNeighborsCount(s, newTransferStep(), opts...)
	}
}

// ByTransfer orders the results by transfer terms.
func ByTransfer(term sql.OrderTerm, terms ...sql.OrderTerm) OrderOption {
	return func(s *sql.Selector) {
		sqlgraph.OrderByNeighborTerms(s, newTransferStep(), append([]sql.OrderTerm{term}, terms...)...)
	}
}
func newTokenTransactionStep() *sqlgraph.Step {
	return sqlgraph.NewStep(
		sqlgraph.From(Table, FieldID),
		sqlgraph.To(TokenTransactionInverseTable, FieldID),
		sqlgraph.Edge(sqlgraph.M2M, true, TokenTransactionTable, TokenTransactionPrimaryKey...),
	)
}
func newTransferStep() *sqlgraph.Step {
	return sqlgraph.NewStep(
		sqlgraph.From(Table, FieldID),
		sqlgraph.To(TransferInverseTable, FieldID),
		sqlgraph.Edge(sqlgraph.O2M, true, TransferTable, TransferColumn),
	)
}
